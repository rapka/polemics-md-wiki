# The Centre for the Study of Existential Risk

![Logo Alt Text Here](https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Picea_abies_shoot_with_buds%2C_Sogndal%2C_Norway.jpg/240px-Picea_abies_shoot_with_buds%2C_Sogndal%2C_Norway.jpg)

[Website](https://www.cser.ac.uk/)

## About

**Org Name** is bla bla bla [^1]

Bla bla bla did _bla bla_ [^2]

> We are an interdisciplinary research centre within the University of Cambridge who study existential risks, develop collaborative strategies to reduce them, and foster a global community of academics, technologists and policy-makers working to safeguard humanity. Our research focuses on biological risks, environmental risks, risks from artificial intelligence, and how to manage extreme technological risk in general.
 
> However, a long-held goal in the field has been the development of artificial intelligence that can learn and adapt to a very broad range of challenges.


Got 2nd place in FLI's world building contest

https://www.cser.ac.uk/news/fli-worldbuilding-contest-joint-cser-cfi-team-awar/ 

> ***Author's Note**: what is this garbage*
 

_To read about one of CSER's current projects,Â Paradigms of Artificial General Intelligence and Their Associated Risks, funded by the [Future of Life Institute](https://futureoflife.org/) through the [FLI International Safety Grants Competition](https://futureoflife.org/2018/07/25/2-million-donated-to-keep-artificial-general-intelligence-beneficial-and-robust/), please click [here](https://www.cser.ac.uk/research/paradigms-AGI/)._


### Leadhership

**CEO:** [bla bla](), also known as co-founder of [bleh]()
**CEO:** [bla bla]()
**CEO:** [bla bla]()

## Finances

### Donors

| Amount        | Donor               | Year |
| ------------- | ------------------- | ---- |
| $10,000       | SBF                 | 2022 |
| $20,000,000   | Open Philanthropy   | 2022 |



### Grants

| Amount        | Recipient           | Purspose           | Year |
| ------------- | ------------------- | ------------------ | ---- |
| $10,000       | SBF                 | AI Safety research | 2020 |
| $20,000,000   | Open Philanthropy   | Global Development | 2022 |





## Controversy

Ceo saidthis:
> There should be no margin below this final sentence.

> _**wtf**: what is this garbage_


* This is an unordered list following a header.
* This is an unordered list following a header.
* This is an unordered list following a header.


---

Text can be **bold**, _italic_, or ~~strikethrough~~. [Links](https://gohugo.io) should be blue with no underlines (unless hovered over).


