# The Centre for the Study of Existential Risk

![Logo Alt Text Here](https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Picea_abies_shoot_with_buds%2C_Sogndal%2C_Norway.jpg/240px-Picea_abies_shoot_with_buds%2C_Sogndal%2C_Norway.jpg)

[Website](https://www.cser.ac.uk/)

## About

**Org Name** is bla bla bla [^1]

Bla bla bla did _bla bla_ [^2]

> We are an interdisciplinary research centre within the University of Cambridge who study existential risks, develop collaborative strategies to reduce them, and foster a global community of academics, technologists and policy-makers working to safeguard humanity. Our research focuses on biological risks, environmental risks, risks from artificial intelligence, and how to manage extreme technological risk in general.
 
> However, a long-held goal in the field has been the development of artificial intelligence that can learn and adapt to a very broad range of challenges.


Got 2nd place in FLI's world building contest

https://www.cser.ac.uk/news/fli-worldbuilding-contest-joint-cser-cfi-team-awar/ 


 

_To read about one of CSER's current projects,Â Paradigms of Artificial General Intelligence and Their Associated Risks, funded by the [Future of Life Institute](https://futureoflife.org/) through the [FLI International Safety Grants Competition](https://futureoflife.org/2018/07/25/2-million-donated-to-keep-artificial-general-intelligence-beneficial-and-robust/), please click [here](https://www.cser.ac.uk/research/paradigms-AGI/)._


### Leadhership

**CEO:** [bla bla](), also known as co-founder of [bleh]()
**CEO:** [bla bla]()
**CEO:** [bla bla]()

## Finances

### Donors





### Grants


## Controversy
