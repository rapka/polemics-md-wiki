---
tags:
  - Spiritia
  - Map2022
---
# Meaningness

[Website](https://meaningness.com/)

Meaningness is a book/website written by David Chapman. Chapman has written several other books as well: [Better Without AI](https://betterwithout.ai/)is about "moderate apocalypses" from AI and [In the Cells of the Eggplant](https://metarationality.com/), an "introduction to metarationality".

### Better Without AI

#### Quotes

##### Ideology

https://betterwithout.ai/spurn-artificial-ideology

>The longer-run solution is **_broad cultural_** understanding that being a slave to any ideology is bad for you and everyone else. This observation is startlingly rare; nearly everyone assumes that you _must_ belong to one. However, it’s obvious once pointed out. Most people are also tired of ideological conflict, and understand that it’s destructive; yet persist because the alternative seems to be surrendering to the Bad Tribe. I am optimistic that anti-ideological understanding could spread rapidly once it gets going.

https://meaningness.com/vaster-than-ideology

> When you [commit](https://meaningness.com/relationships-with-stances#committing "Committing to a stance means resolving to adopt it consistently, whenever the dimension of meaningness it addresses comes up. [Click for details.]") to an [eternalist system](https://meaningness.com/eternalist-systems), what you commit is yourself. Your _self_.
> 
>Ideally, the system _becomes_ your self. You “identify as” a rationalist, an anti-racist ally, or a QAnon digital soldier: you try to view yourself as identical to the system, or to make yourself as nearly as possible into the system’s ideal.[1](https://meaningness.com/vaster-than-ideology#fn_you "This page uses the grammatically indefinite “you” throughout to refer to the protagonist. If it seems accusatory at times, please do not take it personally. Nearly every failing I ascribe to “you” is part of my personal experience. The others are observations of patterns commonly seen in others—from close friends to anonymous online essayists.")
>
>When you commit to a system, it owns you. It’s normal, and passed over without notice, to say that you “belong to” a church or political party. Slavery is illegal, though?


>Leaders can stiffen their spines by putting explicit policies in place ahead of time. For example, company policy could be that, in such a situation, the employee can at worst be suspended for a month pending investigation and judgement according to a defined process, and then fired if appropriate. In response to ideological condemnation, executives can say “we sympathize deeply with your howls of pain, but unfortunately our hands are tied to the mast for the next thirty days.” Probably by then everyone will have forgotten about the whole thing anyway.

_Author's note: This strategy is what police departments_

##### AI Risk

https://betterwithout.ai/AI-is-harmful


> **_Funders_** can shift priority from “find a way to make AI safe” to “find ways to halt unsafe AI research, development, and deployment.”

>**_AI safety organizations_** can call out AI labs’ PR pieces about their safety efforts as drastically inadequate. You can advocate for a slowdown or moratorium on research in its current directions. You can advocate for research toward alternative, inherently safer technologies.


>**_Governments_** can regulate AI, requiring strong evidence of safety before deployment. You can stop funding research that aims to increase AI capabilities without commensurate safety guarantees. You can fund countermeasures such as those recommended in this chapter.

_("Requiring strong evidence" is a very subjective term. Defining it often involves invoking the help of Rationalists.)_