# Centre for the Study of Existential Risk (CSER)

[Website](https://www.cser.ac.uk/) | [Twitter](https://twitter.com/csercambridge)


From their [about page](https://www.cser.ac.uk/about-us/):

> We are an interdisciplinary research centre within the University of Cambridge who study existential risks, develop collaborative strategies to reduce them, and foster a global community of academics, technologists and policy-makers working to safeguard humanity. Our research focuses on biological risks, environmental risks, risks from artificial intelligence, and how to manage extreme technological risk in general.
 
> However, a long-held goal in the field has been the development of artificial intelligence that can learn and adapt to a very broad range of challenges.


A group from CSET got 2nd place in [FLI]()'s world building contest.

https://www.cser.ac.uk/news/fli-worldbuilding-contest-joint-cser-cfi-team-awar/ 


 

_To read about one of CSER's current projects,Â Paradigms of Artificial General Intelligence and Their Associated Risks, funded by the [Future of Life Institute](https://futureoflife.org/) through the [FLI International Safety Grants Competition](https://futureoflife.org/2018/07/25/2-million-donated-to-keep-artificial-general-intelligence-beneficial-and-robust/), please click [here](https://www.cser.ac.uk/research/paradigms-AGI/)._

## Finances

### Donors

(TODO)

