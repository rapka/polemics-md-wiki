---
tags:
  - AI
  - X-Risk
  - Rationality
---
# Conjecture

[Website](https://www.conjecture.dev) | [Twitter](https://twitter.com/ConjectureAI)

Conjecture is an AGI think tank with ties to EleutherAI.

[This Substack post](https://andreamiotti.substack.com/p/agi-in-sight-our-look-at-the-game) written by head of AI Policy  Andrea Miotti and CTO Gabriel Alfour claims that "we are now in the end-game for AGI, and we (humans) are losing" and that humanity should "brace for impact". This piece also references [Eliezer Yudkowsky's](Eliezer%20Yudkowsky.md) ["Death with Dignity"](https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy) LessWrong post, seemingly endorsing his view that humanity is on track for extinction. _Death with Dignity_  was originally posted on April 1st, giving it the potentially to be dismissed as a joke, but this appears to be a genuine endorsement of it.

Additionally, the authors personally endorse the writings of Yudkowsky, Paul Christiano of [Alignment Research Center](../Cartography/Avant-Gardea%20Arriere-Gardea/ARC.md), [MIRI](../Cartography/Lesser%20Wrongia/MIRI.md) president Nate Soares, and LessWronger [John Wentworth](https://www.lesswrong.com/users/johnswentworth).

This post was also posted to [Conjecture's website](https://www.conjecture.dev/research/agi-in-sight-our-look-at-the-game-board), effectively making it the official position of the company. Yudkowsky has also contributed to Conjecture's [Information Hazard Policy](https://www.conjecture.dev/information-hazard-policy)


### MAGIC

In October 2023, Conjecture proposed an AGI regulation mechanism called [Multinational AGI Consortium (MAGIC)](https://www.conjecture.dev/research/multinational-agi-consortium-magic-a-proposal-for-international-coordination-on-ai) which would be "the only organization authorized to train advanced AI models above a certain threshold of computing power". No consideration was paid to the feasibility or logistics of implementing this idea in real life.

>We are campaigning for the creation of a Multinational Artificial General Intelligence Consortium (MAGIC). MAGIC would be an institution built on international collaboration, and the only institution in the world permitted to create advanced AI. By restricting the ability to create AGI to one international body, it can be ensured that AI is created safely, in a secure environment.

>This exclusivity would make any advanced AI development outside of MAGIC illegal, enforced through a global moratorium on training runs using more than a set amount of computing power.Signatory countries to MAGIC would mandate cloud-computing providers, with whom almost all AI companies partner, to prevent any training runs above a specific size within their national jurisdictions. Signatory countries would be responsible for ensuring mutual verification of the enforcement of this measure. Domestically, this would not require the creation of any additional monitoring mechanisms, as cloud providers already track the size of training runs to ensure compliance with their terms of service and for routine business operations.

