---
tags:
  - AI
  - X-Risk
  - Map2023
  - LesserWrongia
---
# Stanford Existential Risks Initiative (SERI)

[website](https://seri.stanford.edu/)

From their website:
>What is an existential risk?
>We think of existential risks, or global catastrophic risks, as risks that could cause the collapse of human civilization or even the extinction of the human species. Prominent examples of human-driven global catastrophic risks include 1) nuclear winter, 2) an infectious disease pandemic engineered by malevolent actors using synthetic biology, 3) catastrophic accidents/misuse involving AI, and 4) climate change and/or environmental degradation creating biological and physical conditions that thriving human civilizations would not survive. Other significant catastrophic risks exist as well.

## Funding

(TODO: research this)